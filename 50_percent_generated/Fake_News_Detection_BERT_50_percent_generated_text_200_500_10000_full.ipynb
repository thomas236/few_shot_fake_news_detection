{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "68f58f96ee7a4499be52adf5720a0545",
            "f097384799644c67abb2a52a3961111c",
            "31545bf19f774138a80eda2aca4fd892",
            "86d1d7748a7d4956971f59f49e82c127",
            "bc4081d5c31c4366b26be8a6556f91d1",
            "ba09d48894054977829d1e7fe96ead4c",
            "67ac76601123405ba0f6e70ca6fabda0",
            "fae0f7ea4e82424d9ca9ec0718309d89",
            "965f17eee64f4f4db1458d31d6136238",
            "f1465cb1645d4db9956fd74b41fe2863",
            "ca47043e6f264d5aad5a4db020525414",
            "8920be847e864f31a0bc0d290da10471",
            "384b458580dc483191604da9a84f4ffc",
            "b95a2e273da048aab014f70c76ad00f1",
            "44c4e1e98b0544f08f7f00355ae7e901",
            "a1c5506d87b04374ab761a3d77101afe",
            "5a3fc0bd42f74410ac09d00da8aac8f3",
            "46a02873e42840c1938e16a25f124e69",
            "a9f9b651547a40c188249d11fbdd4222",
            "52ca9c24cdbe4a538612da0bd55d5e7b",
            "0fcdc2d60e1f41acb6de22cd79c5d6bf",
            "9929c2ac493242a5b6c823da9f1d2ef0",
            "6769dc1b0a784f2fb4195a2727f2e561",
            "f985febe33de4d418305ab2d7a1e41ed",
            "83b0fc3070634fb4806ec13bf4cf3cc0",
            "d5b0a94806804a82a42da2b52eb76176",
            "ab916c67601b4ed0928e10cb5589ab2f",
            "e4683c1743cc49858b13ee54c227b720",
            "417a5deffc694f49a395a1fe5c3ca693",
            "c069719b70e4453cbd031c8aa52999bb",
            "310536dd7de44e25a4b592d4dc3dd747",
            "55460ba75a75443f9e68c5bac5221bc0",
            "11636b1aefd847199f08dde5471057a7",
            "5a8736fdb973427389fbf6b359841baa",
            "630cfebf6c2f49f4ad957bd65bd1f42f",
            "62652b8fd6a44707b1990c6cc3a9b854",
            "d21d5a39a0504451a9b8048ae8d97b7a",
            "f38f14134ed943e986afe0cb15451585",
            "49c57d9b49064478b158517aa2e57694",
            "0b7528cc7cbf474c9df1177f5661d5af",
            "7b0bd4330202476493c10edb11b58728",
            "4d83b25b48394c2f98b4f51e025f24b2",
            "3e783156ac75486c9fea096047c665d9",
            "05a672abbb1247fb914f7a0a6533ae5d"
          ]
        },
        "id": "b64fb204",
        "outputId": "4205c2d9-3416-47c3-d21b-8fe9ea96e0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=0802c79b84b2630d722838d742c62e4ed24bdaa32ff2de46e30565d081b045e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68f58f96ee7a4499be52adf5720a0545"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8920be847e864f31a0bc0d290da10471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6769dc1b0a784f2fb4195a2727f2e561"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a8736fdb973427389fbf6b359841baa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.47      0.74      0.57        19\n",
            "   Real News       0.44      0.20      0.28        20\n",
            "\n",
            "    accuracy                           0.46        39\n",
            "   macro avg       0.46      0.47      0.42        39\n",
            "weighted avg       0.46      0.46      0.42        39\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "\n",
        "package = \"tensorflow\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install - U {package}\n",
        "    importlib.import_module(package)\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"pandas\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"sklearn\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"keras\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"torch\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"langdetect\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from langdetect import detect\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/news_200.csv')\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/200lines_50pcGen.csv\")\n",
        "\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "df = df.dropna(subset=['title'])\n",
        "\n",
        "df1 = df1.dropna(subset=['text'])\n",
        "df1 = df1.dropna(subset=['title'])\n",
        "\n",
        "# Step 3: BERT Tokenization & Formatting\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(dfx, max_len):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        dfx['text'].tolist(),\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "# Tokenize the text\n",
        "max_len = 256  # choose a max length\n",
        "tokens = tokenize_text(df, max_len)\n",
        "tokens1 = tokenize_text(df1, max_len)\n",
        "\n",
        "# Step 4: Model Creation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=2,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "train_inputs, train_labels = train_inputs1, train_labels1\n",
        "\n",
        "\n",
        "# Convert into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "# Create DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=32)\n",
        "\n",
        "# Step 5: Training\n",
        "#optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)  # Add weight decay parameter\n",
        "\n",
        "\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Apply weight decay\n",
        "        #l2_regularization = torch.tensor(0.)\n",
        "        l2_regularization = torch.tensor(0., device=device)\n",
        "        for param in model.parameters():\n",
        "            l2_regularization += torch.norm(param, p=2)\n",
        "\n",
        "\n",
        "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_labels)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Step 6: Evaluation\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = [b.to(device) for b in batch]\n",
        "    b_input_ids, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids)\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# For each input batch, pick the label (0 or 1) with the higher score\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))\n"
      ],
      "id": "b64fb204"
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "package = \"tensorflow\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install - U {package}\n",
        "    importlib.import_module(package)\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"pandas\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"sklearn\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"keras\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"torch\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"langdetect\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from langdetect import detect\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/news_500.csv')\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/500lines_50pcGen.csv\")\n",
        "\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "df = df.dropna(subset=['title'])\n",
        "\n",
        "df1 = df1.dropna(subset=['text'])\n",
        "df1 = df1.dropna(subset=['title'])\n",
        "\n",
        "# Step 3: BERT Tokenization & Formatting\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(dfx, max_len):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        dfx['text'].tolist(),\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "# Tokenize the text\n",
        "max_len = 256  # choose a max length\n",
        "tokens = tokenize_text(df, max_len)\n",
        "tokens1 = tokenize_text(df1, max_len)\n",
        "\n",
        "# Step 4: Model Creation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=2,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "train_inputs, train_labels = train_inputs1, train_labels1\n",
        "\n",
        "\n",
        "# Convert into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "# Create DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=32)\n",
        "\n",
        "# Step 5: Training\n",
        "#optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)  # Add weight decay parameter\n",
        "\n",
        "\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Apply weight decay\n",
        "        #l2_regularization = torch.tensor(0.)\n",
        "        l2_regularization = torch.tensor(0., device=device)\n",
        "        for param in model.parameters():\n",
        "            l2_regularization += torch.norm(param, p=2)\n",
        "\n",
        "\n",
        "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_labels)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Step 6: Evaluation\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = [b.to(device) for b in batch]\n",
        "    b_input_ids, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids)\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# For each input batch, pick the label (0 or 1) with the higher score\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovZFg29tOUYy",
        "outputId": "a3382858-518e-4dcc-ff71-4b5e170351c2"
      },
      "id": "ovZFg29tOUYy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.55      0.98      0.70        54\n",
            "   Real News       0.50      0.02      0.04        45\n",
            "\n",
            "    accuracy                           0.55        99\n",
            "   macro avg       0.52      0.50      0.37        99\n",
            "weighted avg       0.53      0.55      0.40        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "package = \"tensorflow\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install - U {package}\n",
        "    importlib.import_module(package)\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"pandas\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"sklearn\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"keras\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"torch\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"langdetect\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from langdetect import detect\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/news_10000.csv')\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/10000lines_50pcGen.csv\")\n",
        "\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "df = df.dropna(subset=['title'])\n",
        "\n",
        "df1 = df1.dropna(subset=['text'])\n",
        "df1 = df1.dropna(subset=['title'])\n",
        "\n",
        "# Step 3: BERT Tokenization & Formatting\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(dfx, max_len):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        dfx['text'].tolist(),\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "# Tokenize the text\n",
        "max_len = 256  # choose a max length\n",
        "tokens = tokenize_text(df, max_len)\n",
        "tokens1 = tokenize_text(df1, max_len)\n",
        "\n",
        "# Step 4: Model Creation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=2,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "train_inputs, train_labels = train_inputs1, train_labels1\n",
        "\n",
        "\n",
        "# Convert into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "# Create DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=32)\n",
        "\n",
        "# Step 5: Training\n",
        "#optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)  # Add weight decay parameter\n",
        "\n",
        "\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Apply weight decay\n",
        "        #l2_regularization = torch.tensor(0.)\n",
        "        l2_regularization = torch.tensor(0., device=device)\n",
        "        for param in model.parameters():\n",
        "            l2_regularization += torch.norm(param, p=2)\n",
        "\n",
        "\n",
        "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_labels)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Step 6: Evaluation\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = [b.to(device) for b in batch]\n",
        "    b_input_ids, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids)\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# For each input batch, pick the label (0 or 1) with the higher score\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvKan2NpOmPH",
        "outputId": "74c84000-2338-42ff-d1a4-a719710f0f28"
      },
      "id": "EvKan2NpOmPH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.96      0.99      0.98      1029\n",
            "   Real News       0.99      0.96      0.97       912\n",
            "\n",
            "    accuracy                           0.97      1941\n",
            "   macro avg       0.97      0.97      0.97      1941\n",
            "weighted avg       0.97      0.97      0.97      1941\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "package = \"tensorflow\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install - U {package}\n",
        "    importlib.import_module(package)\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"pandas\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"sklearn\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"keras\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"torch\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"transformers\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "package = \"langdetect\"\n",
        "try:\n",
        "    importlib.import_module(package)\n",
        "except ImportError:\n",
        "    !pip install {package}\n",
        "    importlib.import_module(package)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from langdetect import detect\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/full_dataset_50pcGen.csv\")\n",
        "\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "df = df.dropna(subset=['title'])\n",
        "\n",
        "df1 = df1.dropna(subset=['text'])\n",
        "df1 = df1.dropna(subset=['title'])\n",
        "\n",
        "# Step 3: BERT Tokenization & Formatting\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(dfx, max_len):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        dfx['text'].tolist(),\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "# Tokenize the text\n",
        "max_len = 256  # choose a max length\n",
        "tokens = tokenize_text(df, max_len)\n",
        "tokens1 = tokenize_text(df1, max_len)\n",
        "\n",
        "# Step 4: Model Creation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=2,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
        "\n",
        "train_inputs, train_labels = train_inputs1, train_labels1\n",
        "\n",
        "\n",
        "# Convert into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "# Create DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=32)\n",
        "\n",
        "# Step 5: Training\n",
        "#optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)  # Add weight decay parameter\n",
        "\n",
        "\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\"\"\"\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Apply weight decay\n",
        "        #l2_regularization = torch.tensor(0.)\n",
        "        l2_regularization = torch.tensor(0., device=device)\n",
        "        for param in model.parameters():\n",
        "            l2_regularization += torch.norm(param, p=2)\n",
        "\n",
        "\n",
        "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_labels)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Step 6: Evaluation\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = [b.to(device) for b in batch]\n",
        "    b_input_ids, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids)\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# For each input batch, pick the label (0 or 1) with the higher score\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYJf1Z37OuKw",
        "outputId": "694a69fb-04cc-46f5-e5c9-8298a84769cc"
      },
      "id": "YYJf1Z37OuKw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.98      0.99      0.99      2104\n",
            "   Real News       0.99      0.98      0.99      1937\n",
            "\n",
            "    accuracy                           0.99      4041\n",
            "   macro avg       0.99      0.99      0.99      4041\n",
            "weighted avg       0.99      0.99      0.99      4041\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68f58f96ee7a4499be52adf5720a0545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f097384799644c67abb2a52a3961111c",
              "IPY_MODEL_31545bf19f774138a80eda2aca4fd892",
              "IPY_MODEL_86d1d7748a7d4956971f59f49e82c127"
            ],
            "layout": "IPY_MODEL_bc4081d5c31c4366b26be8a6556f91d1"
          }
        },
        "f097384799644c67abb2a52a3961111c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba09d48894054977829d1e7fe96ead4c",
            "placeholder": "​",
            "style": "IPY_MODEL_67ac76601123405ba0f6e70ca6fabda0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "31545bf19f774138a80eda2aca4fd892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae0f7ea4e82424d9ca9ec0718309d89",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965f17eee64f4f4db1458d31d6136238",
            "value": 231508
          }
        },
        "86d1d7748a7d4956971f59f49e82c127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1465cb1645d4db9956fd74b41fe2863",
            "placeholder": "​",
            "style": "IPY_MODEL_ca47043e6f264d5aad5a4db020525414",
            "value": " 232k/232k [00:00&lt;00:00, 535kB/s]"
          }
        },
        "bc4081d5c31c4366b26be8a6556f91d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba09d48894054977829d1e7fe96ead4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ac76601123405ba0f6e70ca6fabda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fae0f7ea4e82424d9ca9ec0718309d89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965f17eee64f4f4db1458d31d6136238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1465cb1645d4db9956fd74b41fe2863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca47043e6f264d5aad5a4db020525414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8920be847e864f31a0bc0d290da10471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384b458580dc483191604da9a84f4ffc",
              "IPY_MODEL_b95a2e273da048aab014f70c76ad00f1",
              "IPY_MODEL_44c4e1e98b0544f08f7f00355ae7e901"
            ],
            "layout": "IPY_MODEL_a1c5506d87b04374ab761a3d77101afe"
          }
        },
        "384b458580dc483191604da9a84f4ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3fc0bd42f74410ac09d00da8aac8f3",
            "placeholder": "​",
            "style": "IPY_MODEL_46a02873e42840c1938e16a25f124e69",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b95a2e273da048aab014f70c76ad00f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f9b651547a40c188249d11fbdd4222",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52ca9c24cdbe4a538612da0bd55d5e7b",
            "value": 28
          }
        },
        "44c4e1e98b0544f08f7f00355ae7e901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fcdc2d60e1f41acb6de22cd79c5d6bf",
            "placeholder": "​",
            "style": "IPY_MODEL_9929c2ac493242a5b6c823da9f1d2ef0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 2.39kB/s]"
          }
        },
        "a1c5506d87b04374ab761a3d77101afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3fc0bd42f74410ac09d00da8aac8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a02873e42840c1938e16a25f124e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9f9b651547a40c188249d11fbdd4222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ca9c24cdbe4a538612da0bd55d5e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fcdc2d60e1f41acb6de22cd79c5d6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9929c2ac493242a5b6c823da9f1d2ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6769dc1b0a784f2fb4195a2727f2e561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f985febe33de4d418305ab2d7a1e41ed",
              "IPY_MODEL_83b0fc3070634fb4806ec13bf4cf3cc0",
              "IPY_MODEL_d5b0a94806804a82a42da2b52eb76176"
            ],
            "layout": "IPY_MODEL_ab916c67601b4ed0928e10cb5589ab2f"
          }
        },
        "f985febe33de4d418305ab2d7a1e41ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4683c1743cc49858b13ee54c227b720",
            "placeholder": "​",
            "style": "IPY_MODEL_417a5deffc694f49a395a1fe5c3ca693",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "83b0fc3070634fb4806ec13bf4cf3cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c069719b70e4453cbd031c8aa52999bb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_310536dd7de44e25a4b592d4dc3dd747",
            "value": 570
          }
        },
        "d5b0a94806804a82a42da2b52eb76176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55460ba75a75443f9e68c5bac5221bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_11636b1aefd847199f08dde5471057a7",
            "value": " 570/570 [00:00&lt;00:00, 52.5kB/s]"
          }
        },
        "ab916c67601b4ed0928e10cb5589ab2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4683c1743cc49858b13ee54c227b720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417a5deffc694f49a395a1fe5c3ca693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c069719b70e4453cbd031c8aa52999bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310536dd7de44e25a4b592d4dc3dd747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55460ba75a75443f9e68c5bac5221bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11636b1aefd847199f08dde5471057a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8736fdb973427389fbf6b359841baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_630cfebf6c2f49f4ad957bd65bd1f42f",
              "IPY_MODEL_62652b8fd6a44707b1990c6cc3a9b854",
              "IPY_MODEL_d21d5a39a0504451a9b8048ae8d97b7a"
            ],
            "layout": "IPY_MODEL_f38f14134ed943e986afe0cb15451585"
          }
        },
        "630cfebf6c2f49f4ad957bd65bd1f42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c57d9b49064478b158517aa2e57694",
            "placeholder": "​",
            "style": "IPY_MODEL_0b7528cc7cbf474c9df1177f5661d5af",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "62652b8fd6a44707b1990c6cc3a9b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0bd4330202476493c10edb11b58728",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d83b25b48394c2f98b4f51e025f24b2",
            "value": 440449768
          }
        },
        "d21d5a39a0504451a9b8048ae8d97b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e783156ac75486c9fea096047c665d9",
            "placeholder": "​",
            "style": "IPY_MODEL_05a672abbb1247fb914f7a0a6533ae5d",
            "value": " 440M/440M [00:00&lt;00:00, 644MB/s]"
          }
        },
        "f38f14134ed943e986afe0cb15451585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c57d9b49064478b158517aa2e57694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b7528cc7cbf474c9df1177f5661d5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b0bd4330202476493c10edb11b58728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d83b25b48394c2f98b4f51e025f24b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e783156ac75486c9fea096047c665d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a672abbb1247fb914f7a0a6533ae5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}