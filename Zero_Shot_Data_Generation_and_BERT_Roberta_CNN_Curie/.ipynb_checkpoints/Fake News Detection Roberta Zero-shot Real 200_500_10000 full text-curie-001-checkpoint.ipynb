{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27408,
     "status": "ok",
     "timestamp": 1692464574287,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "w2Kymp8uoWXZ",
    "outputId": "d9dbf86b-361c-4823-ef73-44f551484a70"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\"\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "package = \"tensorflow\"\n",
    "\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install -U {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"openai\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install --upgrade openai\n",
    "    import openai\n",
    "\n",
    "# Set up OpenAI API\n",
    "API_KEY = \"YOUR API KEY\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "# Load the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "67fc2ff2dbba447baee593e7cf246dcd",
      "7d6f2098354c444480fea2ff93e74cb8",
      "e89afed773484480b4ea9eeb810568b7",
      "b9bc1c80e1874feb95fec32797d747a9",
      "d3c2aae3cc604d38abc286cba4eee50e",
      "7e058c6220ca41f19dbe247c3383daa7",
      "c95e0dc4605741a5a68284f3f6d445dc",
      "e20fac554a5647b3a585959aee233f6a",
      "ceeab32cc287413190daa52e5d441ccf",
      "7b955f9916424c4e89fa00eb2b0faa54",
      "ef3c6c316892455e96567920f973a464",
      "b01c7364d61c4ea8b27080e97d2a3045",
      "466ce6e26c3a4f2d8f95dca27ca96650",
      "fd46c3f2a6694a83b1901a65359bf816",
      "8c9fdaad23fd4cd88262f8f60412b462",
      "5b6846d394f14c3e966e886eeb9917b8",
      "6344666aa7dd4bc596e569c0bd57ce80",
      "0deb679f5d9f4636b02ebb158308806f",
      "f74d100553b44e1d856da4b842f5acf5",
      "e38d8ed34f78464297bb9aa8db47dd09",
      "c8de8132946d4aada54f43ed8c222716",
      "b402d933ccd348e58b0133b7eb328765",
      "ddd6af0536934cdda890186ad8adc87c",
      "ba5adf4e08974573ace5362c50a1665a",
      "00247add0a3c423cb6eec3e59b265e21",
      "e73d37db2bc44ec2afe0fff5803143e2",
      "0b9e53547aca4e5bbd701f3df635dd09",
      "ce824fca47164aa18447fb4eb8f89347",
      "c0b5c8794eb5434787301966baecf29a",
      "52fbc1cdef65447281ff7d2632997738",
      "f8af5cd7cde54d409a03191389cca1b8",
      "75494e7f41494b3ca72571ff6cbf62f4",
      "4b9781b63a6642ec9ca24786a4f6fd78",
      "7ac712296fac4a21b384776739289070",
      "dbfa954ad3234f5c84a71b3ba744fb21",
      "e71681d4f1a244a4a0aee0224d7c57be",
      "ada29e3e8a694c67a55e0d9447b84e2c",
      "0d6225c3d0ae4650a11ef47c2ec94209",
      "fe30ade4cec4440396bd0e5e06dd5004",
      "7e0f5d5c2d69405d8f33d1152348b81e",
      "b720b6e5937f4d7bbf3f5e50633a9232",
      "05b66e2bf766489a8ce37b8248915a3b",
      "cee0c16b50cf483d8d1b0e007fe4a26e",
      "9aa007933f7d40639aeb6f6ca9b8ec85"
     ]
    },
    "executionInfo": {
     "elapsed": 55075,
     "status": "ok",
     "timestamp": 1692464629349,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "BrOouFjtbYxu",
    "outputId": "832bf1b4-2a9f-4565-9021-561d3f19ab40"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "package = \"tensorflow\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install - U {package}\n",
    "    importlib.import_module(package)\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"pandas\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"sklearn\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"keras\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"torch\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"langdetect\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check for the availability of required packages and install it\n",
    "required_packages = ['tensorflow', 'transformers', 'pandas', 'sklearn', 'keras', 'torch', 'langdetect']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "        importlib.import_module(package)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/news_200.csv')\n",
    "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/generated_combined_data200text-curie-001.csv\")\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "df1 = df1.dropna(subset=['text'])\n",
    "df1 = df1.dropna(subset=['title'])\n",
    "\n",
    "# Tokenization and Formatting\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "\n",
    "def tokenize_text(dfx, max_len):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        dfx['text'].str.lower().tolist(),\n",
    "        max_length = max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "max_len = 256  #max length\n",
    "tokens = tokenize_text(df, max_len)\n",
    "tokens1 = tokenize_text(df1, max_len)\n",
    "\n",
    "# Model Creation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "train_inputs, train_labels = train_inputs1, train_labels1\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, random_state=100, test_size=0.1)\n",
    "\n",
    "# Convert into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "# Create DataLoader for the training, testing and validation set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,shuffle  = True)\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
    "\n",
    "best_acc = 0\n",
    "tolerance = 0\n",
    "# Keep track of the validation accuracy for each epoch\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(20):  # maximum of 100 epochs\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Apply weight decay\n",
    "        l2_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, p=2)\n",
    "\n",
    "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # After each epoch, evaluate on validation set\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in val_dataloader:\n",
    "        batch = [b.to(device) for b in batch]\n",
    "        b_input_ids, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "    # Check accuracy\n",
    "    acc = accuracy_score(true_labels, pred_flat)\n",
    "    val_acc_list.append(acc)\n",
    "\n",
    "    print(f'Validation accuracy: {acc}, epoch: {epoch}')\n",
    "\n",
    "    # If this epoch is better than before, reset patience\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        tolerance = 0\n",
    "    else:\n",
    "        # If this epoch did not improve accuracy, increase patience\n",
    "        tolerance += 1\n",
    "        if tolerance > 3:  # no improvement for 3 consecutive epochs\n",
    "            print('Early stopping due to no improvement')\n",
    "            break\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(val_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs. Number of Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = [b.to(device) for b in batch]\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids)\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# For each input batch, pick the label (0 or 1) with the higher score\n",
    "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "executionInfo": {
     "elapsed": 22630,
     "status": "ok",
     "timestamp": 1692464651961,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "dcdRWQPPbaXz",
    "outputId": "a5176ea7-9b85-462d-be7d-2548716d1ae3"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "package = \"tensorflow\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install - U {package}\n",
    "    importlib.import_module(package)\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"pandas\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"sklearn\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"keras\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"torch\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"langdetect\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check for the availability of required packages and install it\n",
    "required_packages = ['tensorflow', 'transformers', 'pandas', 'sklearn', 'keras', 'torch', 'langdetect']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "        importlib.import_module(package)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/news_500.csv')\n",
    "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/generated_combined_data500text-curie-001-3.csv\")\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "df1 = df1.dropna(subset=['text'])\n",
    "df1 = df1.dropna(subset=['title'])\n",
    "\n",
    "# Tokenization and Formatting\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "\n",
    "def tokenize_text(dfx, max_len):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        dfx['text'].str.lower().tolist(),\n",
    "        max_length = max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "max_len = 256  #max length\n",
    "tokens = tokenize_text(df, max_len)\n",
    "tokens1 = tokenize_text(df1, max_len)\n",
    "\n",
    "# Model Creation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "train_inputs, train_labels = train_inputs1, train_labels1\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, random_state=100, test_size=0.1)\n",
    "\n",
    "# Convert into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "# Create DataLoader for the training, testing and validation set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,shuffle  = True)\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
    "\n",
    "best_acc = 0\n",
    "tolerance = 0\n",
    "# Keep track of the validation accuracy for each epoch\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(20):  # maximum of 100 epochs\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Apply weight decay\n",
    "        l2_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, p=2)\n",
    "\n",
    "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # After each epoch, evaluate on validation set\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in val_dataloader:\n",
    "        batch = [b.to(device) for b in batch]\n",
    "        b_input_ids, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "    # Check accuracy\n",
    "    acc = accuracy_score(true_labels, pred_flat)\n",
    "    val_acc_list.append(acc)\n",
    "\n",
    "    print(f'Validation accuracy: {acc}, epoch: {epoch}')\n",
    "\n",
    "    # If this epoch is better than before, reset patience\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        tolerance = 0\n",
    "    else:\n",
    "        # If this epoch did not improve accuracy, increase patience\n",
    "        tolerance += 1\n",
    "        if tolerance > 3:  # no improvement for 3 consecutive epochs\n",
    "            print('Early stopping due to no improvement')\n",
    "            break\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(val_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs. Number of Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = [b.to(device) for b in batch]\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids)\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# For each input batch, pick the label (0 or 1) with the higher score\n",
    "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 474251,
     "status": "ok",
     "timestamp": 1692467682364,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "5MkDr2AdNR5c",
    "outputId": "2b2bf1d2-be75-4a69-ca33-1f61212d462d"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "package = \"tensorflow\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install - U {package}\n",
    "    importlib.import_module(package)\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"pandas\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"sklearn\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"keras\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"torch\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"langdetect\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check for the availability of required packages and install it\n",
    "required_packages = ['tensorflow', 'transformers', 'pandas', 'sklearn', 'keras', 'torch', 'langdetect']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "        importlib.import_module(package)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/news_10000.csv')\n",
    "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/generated_combined_data10000text-curie-001.csv\")\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "df1 = df1.dropna(subset=['text'])\n",
    "df1 = df1.dropna(subset=['title'])\n",
    "\n",
    "# Tokenization and Formatting\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "\n",
    "def tokenize_text(dfx, max_len):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        dfx['text'].str.lower().tolist(),\n",
    "        max_length = max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "max_len = 256  #max length\n",
    "tokens = tokenize_text(df, max_len)\n",
    "tokens1 = tokenize_text(df1, max_len)\n",
    "\n",
    "# Model Creation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "train_inputs, train_labels = train_inputs1, train_labels1\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, random_state=100, test_size=0.1)\n",
    "\n",
    "# Convert into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "# Create DataLoader for the training, testing and validation set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,shuffle  = True)\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
    "\n",
    "best_acc = 0\n",
    "tolerance = 0\n",
    "# Keep track of the validation accuracy for each epoch\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(20):  # maximum of 100 epochs\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Apply weight decay\n",
    "        l2_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, p=2)\n",
    "\n",
    "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # After each epoch, evaluate on validation set\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in val_dataloader:\n",
    "        batch = [b.to(device) for b in batch]\n",
    "        b_input_ids, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "    # Check accuracy\n",
    "    acc = accuracy_score(true_labels, pred_flat)\n",
    "    val_acc_list.append(acc)\n",
    "\n",
    "    print(f'Validation accuracy: {acc}, epoch: {epoch}')\n",
    "\n",
    "    # If this epoch is better than before, reset patience\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        tolerance = 0\n",
    "    else:\n",
    "        # If this epoch did not improve accuracy, increase patience\n",
    "        tolerance += 1\n",
    "        if tolerance > 3:  # no improvement for 3 consecutive epochs\n",
    "            print('Early stopping due to no improvement')\n",
    "            break\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(val_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs. Number of Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = [b.to(device) for b in batch]\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids)\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# For each input batch, pick the label (0 or 1) with the higher score\n",
    "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "executionInfo": {
     "elapsed": 1447458,
     "status": "ok",
     "timestamp": 1692467208126,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "Fl7ixBGYVKSy",
    "outputId": "35ebc6b1-439b-42a2-cf6c-ff76599a0573"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "package = \"tensorflow\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install - U {package}\n",
    "    importlib.import_module(package)\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"pandas\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"sklearn\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"keras\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"torch\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"transformers\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "package = \"langdetect\"\n",
    "try:\n",
    "    importlib.import_module(package)\n",
    "except ImportError:\n",
    "    !pip install {package}\n",
    "    importlib.import_module(package)\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check for the availability of required packages and install it\n",
    "required_packages = ['tensorflow', 'transformers', 'pandas', 'sklearn', 'keras', 'torch', 'langdetect']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "        importlib.import_module(package)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/train.csv')\n",
    "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Zero_Shot_Data_Generation_and_BERT_Roberta_CNN_Curie/train_curie_20400.csv\")\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "df1 = df1.dropna(subset=['text'])\n",
    "df1 = df1.dropna(subset=['title'])\n",
    "\n",
    "# Tokenization and Formatting\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "\n",
    "def tokenize_text(dfx, max_len):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        dfx['text'].str.lower().tolist(),\n",
    "        max_length = max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "max_len = 256  #max length\n",
    "tokens = tokenize_text(df, max_len)\n",
    "tokens1 = tokenize_text(df1, max_len)\n",
    "\n",
    "# Model Creation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(tokens['input_ids'], df['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_inputs1, test_inputs1, train_labels1, test_labels1 = train_test_split(tokens1['input_ids'], df1['label'].values, random_state=100, test_size=0.2)\n",
    "\n",
    "train_inputs, train_labels = train_inputs1, train_labels1\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, random_state=100, test_size=0.1)\n",
    "\n",
    "# Convert into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "# Create DataLoader for the training, testing and validation set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,shuffle  = True)\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)  # Add weight decay parameter\n",
    "\n",
    "best_acc = 0\n",
    "tolerance = 0\n",
    "# Keep track of the validation accuracy for each epoch\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(20):  # maximum of 100 epochs\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Apply weight decay\n",
    "        l2_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, p=2)\n",
    "\n",
    "        loss += 0.01 * l2_regularization  # Adjust the weight decay factor\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # After each epoch, evaluate on validation set\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in val_dataloader:\n",
    "        batch = [b.to(device) for b in batch]\n",
    "        b_input_ids, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "    # Check accuracy\n",
    "    acc = accuracy_score(true_labels, pred_flat)\n",
    "    val_acc_list.append(acc)\n",
    "\n",
    "    print(f'Validation accuracy: {acc}, epoch: {epoch}')\n",
    "\n",
    "    # If this epoch is better than before, reset patience\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        tolerance = 0\n",
    "    else:\n",
    "        # If this epoch did not improve accuracy, increase patience\n",
    "        tolerance += 1\n",
    "        if tolerance > 3:  # no improvement for 3 consecutive epochs\n",
    "            print('Early stopping due to no improvement')\n",
    "            break\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(val_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs. Number of Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = [b.to(device) for b in batch]\n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids)\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "# Flatten the predictions and true values for aggregate evaluation on the whole dataset\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# For each input batch, pick the label (0 or 1) with the higher score\n",
    "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred_flat, target_names=['Fake News', 'Real News']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1692465424162,
     "user": {
      "displayName": "Thomas Sebastian",
      "userId": "15795710734502513346"
     },
     "user_tz": 240
    },
    "id": "aByF7HIWSHeX"
   },
   "outputs": [],
   "source": [
    "\"\"\"import glob\n",
    "\n",
    "# Get a list of all the csv files\n",
    "files = glob.glob('/content/drive/MyDrive/Colab Notebooks/*combined*curie*.csv')\n",
    "print (files)\n",
    "files.sort()  # This line is optional. Use it if you want to sort the files.\n",
    "\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/train_curie.csv', 'w') as outfile:\n",
    "    for i, filename in enumerate(files):\n",
    "        with open(filename, 'r') as infile:\n",
    "            lines = infile.readlines()\n",
    "            if i == 0:  # For the first file write all lines\n",
    "                outfile.writelines(lines)\n",
    "            else:  # For other files skip the first line\n",
    "                outfile.writelines(lines[1:])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qqPrry2Nnu4"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7oY3dvQY6F7rBLxMpuLhc",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1suEb1FYGKBJs0d9bq7uRu-bbJ05F1bdi",
     "timestamp": 1692462877004
    },
    {
     "file_id": "12ZiF8A539YGaUqQwLh3NQlLT4WPFee6E",
     "timestamp": 1690492436854
    },
    {
     "file_id": "1tDCAxu1uWV-jgekuzhphOQKZZYmcg6JW",
     "timestamp": 1688325177473
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00247add0a3c423cb6eec3e59b265e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52fbc1cdef65447281ff7d2632997738",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8af5cd7cde54d409a03191389cca1b8",
      "value": 481
     }
    },
    "05b66e2bf766489a8ce37b8248915a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b9e53547aca4e5bbd701f3df635dd09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d6225c3d0ae4650a11ef47c2ec94209": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0deb679f5d9f4636b02ebb158308806f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "466ce6e26c3a4f2d8f95dca27ca96650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6344666aa7dd4bc596e569c0bd57ce80",
      "placeholder": "",
      "style": "IPY_MODEL_0deb679f5d9f4636b02ebb158308806f",
      "value": "Downloading ()olve/main/merges.txt: 100%"
     }
    },
    "4b9781b63a6642ec9ca24786a4f6fd78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52fbc1cdef65447281ff7d2632997738": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b6846d394f14c3e966e886eeb9917b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6344666aa7dd4bc596e569c0bd57ce80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67fc2ff2dbba447baee593e7cf246dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d6f2098354c444480fea2ff93e74cb8",
       "IPY_MODEL_e89afed773484480b4ea9eeb810568b7",
       "IPY_MODEL_b9bc1c80e1874feb95fec32797d747a9"
      ],
      "layout": "IPY_MODEL_d3c2aae3cc604d38abc286cba4eee50e"
     }
    },
    "75494e7f41494b3ca72571ff6cbf62f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ac712296fac4a21b384776739289070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbfa954ad3234f5c84a71b3ba744fb21",
       "IPY_MODEL_e71681d4f1a244a4a0aee0224d7c57be",
       "IPY_MODEL_ada29e3e8a694c67a55e0d9447b84e2c"
      ],
      "layout": "IPY_MODEL_0d6225c3d0ae4650a11ef47c2ec94209"
     }
    },
    "7b955f9916424c4e89fa00eb2b0faa54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d6f2098354c444480fea2ff93e74cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e058c6220ca41f19dbe247c3383daa7",
      "placeholder": "",
      "style": "IPY_MODEL_c95e0dc4605741a5a68284f3f6d445dc",
      "value": "Downloading ()olve/main/vocab.json: 100%"
     }
    },
    "7e058c6220ca41f19dbe247c3383daa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e0f5d5c2d69405d8f33d1152348b81e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c9fdaad23fd4cd88262f8f60412b462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8de8132946d4aada54f43ed8c222716",
      "placeholder": "",
      "style": "IPY_MODEL_b402d933ccd348e58b0133b7eb328765",
      "value": " 456k/456k [00:00&lt;00:00, 34.5MB/s]"
     }
    },
    "9aa007933f7d40639aeb6f6ca9b8ec85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ada29e3e8a694c67a55e0d9447b84e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cee0c16b50cf483d8d1b0e007fe4a26e",
      "placeholder": "",
      "style": "IPY_MODEL_9aa007933f7d40639aeb6f6ca9b8ec85",
      "value": " 499M/499M [00:00&lt;00:00, 515MB/s]"
     }
    },
    "b01c7364d61c4ea8b27080e97d2a3045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_466ce6e26c3a4f2d8f95dca27ca96650",
       "IPY_MODEL_fd46c3f2a6694a83b1901a65359bf816",
       "IPY_MODEL_8c9fdaad23fd4cd88262f8f60412b462"
      ],
      "layout": "IPY_MODEL_5b6846d394f14c3e966e886eeb9917b8"
     }
    },
    "b402d933ccd348e58b0133b7eb328765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b720b6e5937f4d7bbf3f5e50633a9232": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9bc1c80e1874feb95fec32797d747a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b955f9916424c4e89fa00eb2b0faa54",
      "placeholder": "",
      "style": "IPY_MODEL_ef3c6c316892455e96567920f973a464",
      "value": " 899k/899k [00:00&lt;00:00, 35.3MB/s]"
     }
    },
    "ba5adf4e08974573ace5362c50a1665a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce824fca47164aa18447fb4eb8f89347",
      "placeholder": "",
      "style": "IPY_MODEL_c0b5c8794eb5434787301966baecf29a",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "c0b5c8794eb5434787301966baecf29a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8de8132946d4aada54f43ed8c222716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c95e0dc4605741a5a68284f3f6d445dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce824fca47164aa18447fb4eb8f89347": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cee0c16b50cf483d8d1b0e007fe4a26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ceeab32cc287413190daa52e5d441ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3c2aae3cc604d38abc286cba4eee50e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbfa954ad3234f5c84a71b3ba744fb21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe30ade4cec4440396bd0e5e06dd5004",
      "placeholder": "",
      "style": "IPY_MODEL_7e0f5d5c2d69405d8f33d1152348b81e",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "ddd6af0536934cdda890186ad8adc87c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba5adf4e08974573ace5362c50a1665a",
       "IPY_MODEL_00247add0a3c423cb6eec3e59b265e21",
       "IPY_MODEL_e73d37db2bc44ec2afe0fff5803143e2"
      ],
      "layout": "IPY_MODEL_0b9e53547aca4e5bbd701f3df635dd09"
     }
    },
    "e20fac554a5647b3a585959aee233f6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38d8ed34f78464297bb9aa8db47dd09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e71681d4f1a244a4a0aee0224d7c57be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b720b6e5937f4d7bbf3f5e50633a9232",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05b66e2bf766489a8ce37b8248915a3b",
      "value": 498818054
     }
    },
    "e73d37db2bc44ec2afe0fff5803143e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75494e7f41494b3ca72571ff6cbf62f4",
      "placeholder": "",
      "style": "IPY_MODEL_4b9781b63a6642ec9ca24786a4f6fd78",
      "value": " 481/481 [00:00&lt;00:00, 43.2kB/s]"
     }
    },
    "e89afed773484480b4ea9eeb810568b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e20fac554a5647b3a585959aee233f6a",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ceeab32cc287413190daa52e5d441ccf",
      "value": 898823
     }
    },
    "ef3c6c316892455e96567920f973a464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f74d100553b44e1d856da4b842f5acf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8af5cd7cde54d409a03191389cca1b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd46c3f2a6694a83b1901a65359bf816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f74d100553b44e1d856da4b842f5acf5",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e38d8ed34f78464297bb9aa8db47dd09",
      "value": 456318
     }
    },
    "fe30ade4cec4440396bd0e5e06dd5004": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
